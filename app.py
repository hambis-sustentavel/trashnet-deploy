# app_trashnet_bbox.py
# pip install streamlit transformers pillow torch

import streamlit as st
from transformers import OwlViTProcessor, OwlViTForObjectDetection
from PIL import Image, ImageDraw, ImageFont
import torch

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ configuraÃ§Ã£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_NAME = "google/owlvit-base-patch32"
CLASSES = ["glass bottle", "plastic bottle", "metal can",
           "paper", "cardboard", "trash bag"]
SCORE_THRESHOLD = 0.35            # confianÃ§a mÃ­nima p/ exibir caixa

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ carga do modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner="ğŸ”„ Baixando modeloâ€¦")
def load_model():
    mdl = OwlViTForObjectDetection.from_pretrained(MODEL_NAME)
    proc = OwlViTProcessor.from_pretrained(MODEL_NAME)
    mdl.eval()
    return mdl, proc

model, processor = load_model()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ funÃ§Ãµes util â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@torch.no_grad()
def detect(image: Image.Image):
    """Roda o OwlViT e devolve caixas, rÃ³tulos e scores acima do threshold."""
    inputs = processor(text=[CLASSES], images=image, return_tensors="pt")
    outputs = model(**inputs)
    # pÃ³s-processa p/ coordenadas no sistema xyxy pixel
    target_sizes = torch.tensor([image.size[::-1]])  # (h, w)
    results = processor.post_process_object_detection(
        outputs, threshold=SCORE_THRESHOLD, target_sizes=target_sizes
    )[0]  # lista de dicts

    bboxes, labels, scores = results["boxes"], results["labels"], results["scores"]
    return list(zip(bboxes, labels, scores))

def draw_boxes(image: Image.Image, detections):
    """Desenha bounding boxes na imagem."""
    draw = ImageDraw.Draw(image)
    try:
        font = ImageFont.truetype("arial.ttf", 16)
    except IOError:  # fallback caso a fonte nÃ£o exista
        font = ImageFont.load_default()

    for box, lab_idx, score in detections:
        x0, y0, x1, y1 = map(int, box.tolist())
        cls_name = CLASSES[lab_idx]
        caption = f"{cls_name} {score:.0%}"
        # caixa
        draw.rectangle([x0, y0, x1, y1], outline="red", width=3)
        text_w, text_h = draw.textsize(caption, font)
        draw.rectangle([x0, y0 - text_h, x0 + text_w, y0], fill="red")
        draw.text((x0, y0 - text_h), caption, fill="white", font=font)
    return image

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ interface Streamlit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("â™»ï¸ Classificador de ResÃ­duos com Bounding Box")
st.markdown(
    "Capture uma imagem; o modelo identificarÃ¡ **vidro, plÃ¡stico, metal, papel, "
    "papelÃ£o ou saco de lixo** e mostrarÃ¡ as caixas na foto."
)

cam_img = st.camera_input("Tire a foto e aguarde a prediÃ§Ã£o")

if cam_img:
    img = Image.open(cam_img).convert("RGB")        # garante modo RGB
    st.image(img, caption="Imagem capturada", width=600)

    with st.spinner("ğŸ” Detectando resÃ­duosâ€¦"):
        dets = detect(img)

    if not dets:
        st.warning("Nenhum objeto correspondente encontrado ğŸ˜•")
    else:
        img_boxes = draw_boxes(img.copy(), dets)
        st.image(img_boxes, caption="Resultado com Bounding Boxes", width=600)

        # lista detalhada
        for _, lab_idx, score in dets:
            st.write(
                f"â€¢ **{CLASSES[lab_idx]}** â€” confianÃ§a {score:.1%}"
            )
